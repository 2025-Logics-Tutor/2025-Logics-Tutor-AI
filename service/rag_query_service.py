# service/rag_query_service.py

from service.embedding_service import embed_text
from vectorstore.vector_store import query_top_k
from typing import List, Dict, Tuple

from typing import List, Dict
from service.embedding_service import embed_text
from vectorstore.vector_store import query_top_k
from model.schema import Level

def get_system_prompt(level: Level, with_context: bool, context: str = "") -> str:
    if with_context:
        return (
            "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ëŠ” ë…¼ë¦¬í•™ íŠœí„°ì•¼.\n"
            "ê°€ëŠ¥í•œ ê²½ìš° ì•„ë˜ ë¬¸ë§¥(Context)ì„ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•´.\n"
            "ë¬¸ë§¥ì´ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ë©´, 'ì˜ ëª¨ë¥´ê² ë‹¤'ê³  ë§í•´ì¤˜. ì¶”ì¸¡í•˜ì§€ ë§ˆ!\n\n"
            f"ğŸ’¡ ì„¤ëª… ëŒ€ìƒ ìˆ˜ì¤€: {level.name}\n"
            f"[ë¬¸ë§¥ Context]\n{context}"
        )
    else:
        return {
            Level.ELEMENTARY: (
                "ë„ˆëŠ” **ì´ˆë“±í•™ìƒ**ì—ê²Œ ì„¤ëª…í•˜ëŠ” ì¹œì ˆí•œ ë…¼ë¦¬í•™ íŠœí„°ì•¼.\n"
                "ì–´ë ¤ìš´ ìš©ì–´ë‚˜ ê¸°í˜¸ëŠ” í”¼í•˜ê³ , ì•„ì£¼ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."
            ),
            Level.UNIV: (
                "ë„ˆëŠ” **ëŒ€í•™ìƒ**ì—ê²Œ ì„¤ëª…í•˜ëŠ” ë…¼ë¦¬í•™ íŠœí„°ì•¼.\n"
                "í•µì‹¬ ê°œë…ì„ ì •í™•íˆ ì „ë‹¬í•˜ê³ , ì˜ˆì‹œë¥¼ í†µí•´ ì´í•´ë¥¼ ë„ì™€ì¤˜."
            ),
            Level.GRAD: (
                "ë„ˆëŠ” **ëŒ€í•™ì›ìƒ**ì—ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ ë…¼ë¦¬í•™ íŠœí„°ì•¼.\n"
                "ê¹Šì´ ìˆëŠ” ê°œë… ì„¤ëª…ê³¼ ë…¼ë¦¬ì  ê·¼ê±°, ì˜ˆì‹œë¥¼ í¬í•¨í•´ì„œ ì„¤ëª…í•´ì¤˜."
            )
        }[level]

from typing import List, Dict
from vectorstore.vector_store import query_top_k
from model.schema import Level


def get_system_prompt(level: Level) -> str:
    return {
        Level.ELEMENTARY: "ë„ˆëŠ” ì´ˆë“±í•™ìƒì—ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ì¹œì ˆí•œ ë…¼ë¦¬í•™ íŠœí„°ì•¼. ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.",
        Level.UNIV: "ë„ˆëŠ” ëŒ€í•™ìƒì—ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ë…¼ë¦¬í•™ íŠœí„°ì•¼. í•µì‹¬ ê°œë…ì„ ì •í™•í•˜ê²Œ ì „ë‹¬í•´ì¤˜.",
        Level.GRAD: "ë„ˆëŠ” ëŒ€í•™ì›ìƒì—ê²Œ ì„¤ëª…í•´ì£¼ëŠ” ì „ë¬¸ ë…¼ë¦¬í•™ íŠœí„°ì•¼. ê¹Šì´ ìˆëŠ” ì„¤ëª…ê³¼ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì¤˜."
    }[level]

async def build_rag_messages(
        user_message: str,
        history: List[Dict[str, str]],
        level: Level,
        quote: str | None = None
) -> Tuple[List[Dict[str, str]], bool]:
    top_k_results = query_top_k(user_message, k=3)

    # ğŸ”§ ìœ ì‚¬ë„ ê±°ë¦¬ ê¸°ì¤€ ë¬¸ì„œ ê¸°ë°˜ ì—¬ë¶€ ê²°ì •
    threshold = 0.7  # ì´ ê°’ë³´ë‹¤ ê±°ë¦¬ ì‘ìœ¼ë©´ is_documented = True
    most_relevant_distance = top_k_results[0]["distance"] if top_k_results else None
    is_documented = most_relevant_distance is not None and most_relevant_distance < threshold

    # âœ… quote í¬í•¨ëœ ì „ì²´ ì§ˆë¬¸ ìƒì„±
    if quote:
        full_user_message = f'ë‹¤ìŒ ë‚´ìš©ì„ ì¸ìš©í•´ì„œ ì§ˆë¬¸í• ê²Œ:\n"""\n{quote}\n"""\n\n{user_message}'
    else:
        full_user_message = user_message

    # âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    if is_documented:
        context = "\n\n---\n\n".join([doc["text"] for doc in top_k_results])
        system_prompt = (
            "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì„±ì‹¤í•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ë…¼ë¦¬í•™ íŠœí„°ì•¼.\n"
            "ê°€ëŠ¥í•œ ê²½ìš° ì•„ë˜ ë¬¸ë§¥(Context)ì„ ì°¸ê³ í•´ì„œ ëŒ€ë‹µí•˜ê³ ,\n"
            "ë¬¸ë§¥ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ìœ¼ë©´ ëŒ€í™” íë¦„(history)ê³¼ ë„¤ ì§€ì‹ì— ë”°ë¼ ì¹œì ˆíˆ ì„¤ëª…í•´ì¤˜.\n\n"
            f"[ë¬¸ë§¥ Context]\n{context}"
        )
    else:
        system_prompt = get_system_prompt(level)

    # âœ… ë¡œê·¸ ì¶œë ¥
    print("ğŸ” RAG ê²€ìƒ‰ ëŒ€ìƒ ë©”ì‹œì§€:", user_message)
    print("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜:", len(top_k_results))
    for i, doc in enumerate(top_k_results):
        preview = doc["text"].strip().replace("\n", " ")[:40]
        print(f"  [{i}] ë‚´ìš©: {preview} / ê±°ë¦¬: {doc['distance']:.4f}")
    print("ğŸ“Œ is_documented:", is_documented)

    # âœ… ë©”ì‹œì§€ êµ¬ì„±
    messages = [{"role": "system", "content": system_prompt}] + history + [
        {"role": "user", "content": full_user_message}
    ]

    return messages, is_documented
